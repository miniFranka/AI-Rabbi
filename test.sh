CUDA_VISIBLE_DEVICES=0 llamafactory-cli webchat \
    --model_name_or_path /root/autodl-tmp/project/lzy/jew/Meta-Llama-3-8B-Instruct \
    --template llama3